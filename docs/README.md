# KISYSTEM
## KI-gestÃ¼tztes Entwicklungssystem fÃ¼r U3DAW (Universal 3D Audio Workstation)

**Version:** Phase 7 (RUN 32)  
**Status:** ğŸš€ Production Ready - Meta-Supervisor Implementation  
**Developer:** JÃ¶rg Bohne / Bohne Audio  
**Location:** Engelskirchen, Germany  
**Last Updated:** 2025-11-10

---

## ğŸ¯ Was ist KISYSTEM?

KISYSTEM ist ein **autonomes, lernfÃ¤higes Multi-Agent-Entwicklungssystem** zur Beschleunigung der Entwicklung von **U3DAW** - einer GPU-beschleunigten Audio-Workstation mit revolutionÃ¤rer **TEP-Technologie** (Time-Energy Processing).

### Hauptziele

1. **Autonome Code-Generierung** - CUDA-Kernels, C++ Audio-DSP, Python-Tools
2. **Intelligentes Learning** - Fehler werden nie wiederholt, LÃ¶sungen kontextabhÃ¤ngig wiederverwendet
3. **Hardware-in-the-Loop Testing** - Direkter Test auf RME MADI FX + RTX 4070
4. **Performance-Optimierung** - Automatische GPU-Profiling und Iterative Verbesserung
5. **Kosteneffizienz** - 7-Modell-Routing mit ROI-basierter Priorisierung

---

## ğŸ†• Phase 7 Features (RUN 32)

### Meta-Supervisor
**Data-driven Prioritization & Model Selection**
- Analysiert Learning-DB und berechnet Task-PrioritÃ¤ten
- Empfiehlt optimale Startmodelle basierend auf Erfolgshistorie
- Formula: `P(d) = 0.5(1-sr) + 0.2/(1+t) + 0.2Â·min(1, c/20) + 0.1Â·R`
- Read-only Modus: Keine Ã„nderungen an DB, nur Analyse

### 7-Modell-Routing mit Stop-Loss
**Domain-spezifische Eskalationsketten**

| Domain | Start | Eskalation (2 Fails â†’ Next) |
|--------|-------|----------------------------|
| CUDA / Kernel | `qwen2.5-coder:32b` | â†’ `deepseek-r1:32b` â†’ `deepseek-coder-v2:16b` |
| C++ / System | `deepseek-coder-v2:16b` | â†’ `qwen2.5-coder:32b` â†’ `deepseek-r1:32b` |
| Audio / DSP | `deepseek-coder-v2:16b` | â†’ `qwen2.5-coder:32b` â†’ `deepseek-r1:32b` |
| Tests / Docs | `phi4:latest` | â†’ `mistral:7b` â†’ `llama3.1:8b` |
| Planning | `qwen2.5:32b` | â†’ `deepseek-r1:32b` â†’ `mistral:7b` |

**Stop-Loss:** 2 Fehler pro Modell â†’ Automatische Eskalation

### Hybrid Decision Logic
**Weighted Model Selection**
```
Final_Model = 0.40Â·Meta_Bias + 0.30Â·Complexity + 0.30Â·Failure_State
```
- Meta-Bias: Evidenz aus Learning-DB (success_rate â‰¥ 0.65, count â‰¥ 5)
- Complexity: CUDA/C++ KomplexitÃ¤tsdetektor
- Failure-State: Aktueller Retry-/Eskalations-Level

### Two-Tier-Profiling
**Performance-Optimierung ohne Overhead**
- **Tier 0:** Microbench (ohne nsys) - Schnelles Feedback <5s
- **Tier 1:** Vollprofil (mit nsys) - Nur bei relevanter AktivitÃ¤t
- **Ergebnis:** 40-55% Zeitersparnis bei gleichem Insight

### Cost-Aware Queue
**ROI-basierte Task-Priorisierung**
```
Priority_Eff = Priority_Score / ETA(Model, Domain)
```
Tasks mit hÃ¶chstem Return-on-Investment werden zuerst ausgefÃ¼hrt.

---

## ğŸ—ï¸ Architektur

### Core Components

```
KISYSTEM/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ meta_supervisor.py          [Phase 7 - NEU]
â”‚   â”œâ”€â”€ hybrid_decision.py          [Phase 7 - NEU]
â”‚   â”œâ”€â”€ error_categorizer.py        [Phase 7 - Separate Module]
â”‚   â”œâ”€â”€ learning_module_v2.py       [Context-Aware Learning]
â”‚   â”œâ”€â”€ confidence_scorer.py        [Multi-Faktor Scoring]
â”‚   â”œâ”€â”€ model_selector.py           [7-Model-Routing]
â”‚   â”œâ”€â”€ performance_parser.py       [GPU Metrics Extraction]
â”‚   â””â”€â”€ workflow_engine.py          [Auto-Dependency Management]
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ builder_agent.py            [Code-Generierung]
â”‚   â”œâ”€â”€ fixer_agent.py              [Error-Fixing mit Template-Memory]
â”‚   â”œâ”€â”€ tester_agent.py             [Execution & Validation]
â”‚   â”œâ”€â”€ cuda_profiler_agent.py      [GPU Performance Analysis]
â”‚   â”œâ”€â”€ search_agent_v2.py          [Web-Research bei Deadlock]
â”‚   â”œâ”€â”€ review_agent_v2.py          [Code-Review]
â”‚   â”œâ”€â”€ docs_agent_v2.py            [Documentation]
â”‚   â””â”€â”€ hardware_test_agent.py      [RME/GPU Testing]
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ kisystem_config.json
â”‚   â””â”€â”€ optimization_config.json    [Phase 7 - NEU]
â”‚
â””â”€â”€ supervisor_v3.py                [Orchestration]
```

### Agent-Workflow

```
User Task
    â†“
[Supervisor V3] â†’ Parse & Route
    â†“
[Meta-Supervisor] â†’ Analyze Priority & Recommend Model
    â†“
[Hybrid Decision] â†’ Select Optimal Start Model
    â†“
[Builder Agent] â†’ Generate Code (mit selected model)
    â†“
[Tester Agent] â†’ Execute & Validate
    â†“
SUCCESS? â†’ [Learning Module] â†’ Store Solution
    â†“ NO
[Error Categorizer] â†’ Classify Error (Compilation/Runtime/Performance/Logic)
    â†“
[Fixer Agent] â†’ Fix mit Next Model (Stop-Loss Escalation)
    â†“
[Tester Agent] â†’ Re-Test
    â†“
Loop bis Success oder Max Retries
    â†“
[CUDA Profiler] â†’ Two-Tier Performance Analysis (if applicable)
    â†“
[Learning Module] â†’ Update Statistics fÃ¼r Meta-Supervisor
```

---

## ğŸ–¥ï¸ Hardware Setup

### Development System
- **CPU:** AMD Ryzen 9 7900 (12-core, 24-thread)
- **GPU:** NVIDIA RTX 4070 (12GB VRAM, CUDA 13.0)
- **RAM:** 64GB DDR5-6000
- **Storage:** Samsung 990 PRO 2TB SSD
- **OS:** Windows 10 IoT Enterprise LTSC
- **IDE:** Visual Studio 2022 + Python 3.11

### Audio Hardware
- **Interface:** RME HDSPe MADI FX (PCIe)
  - 32 KanÃ¤le @ 192kHz (Optical MADI)
  - <2ms Round-Trip Latency
- **Converters:** 
  - M-32 AD (16 EingÃ¤nge @ 192kHz/32-bit)
  - M-32 DA (32 AusgÃ¤nge @ 192kHz/32-bit)
- **Speaker System:** 9.1.6 Immersive (4-Way Active Front + DBA Subs)
  - Bohne Audio Patented Ribbon Tweeters
  - 4x RCF LN19S400 (21") Subwoofer Array
  - Target SPL: 110dB @ Sweet Spot

### Ollama Models (7 Total)
| Model | Size | Use Case | Timeout |
|-------|------|----------|---------|
| `llama3.1:8b` | 4.9 GB | Trivial/Boilerplate | 180s |
| `mistral:7b` | 4.4 GB | Generic/Quick | 240s |
| `phi4:latest` | 9.1 GB | Tests/Docs | 240s |
| `deepseek-coder-v2:16b` | 8.9 GB | Mid-Level Code | 300s |
| `qwen2.5:32b` | 19 GB | Reasoning | 900s |
| `qwen2.5-coder:32b` | 19 GB | Complex CUDA | 1800s |
| `deepseek-r1:32b` | 19 GB | Deep Fixes | 1800s |

---

## ğŸš€ Quick Start

### Installation

```powershell
# 1. Clone Repository
git clone https://github.com/JoeBoh71/KISYSTEM.git
cd KISYSTEM

# 2. Install Dependencies
pip install -r requirements.txt --break-system-packages

# 3. Initialize Learning Database
python -c "from core.learning_module_v2 import LearningModule; LearningModule()"

# 4. Configure Ollama Models
ollama pull qwen2.5-coder:32b
ollama pull deepseek-r1:32b
ollama pull deepseek-coder-v2:16b
ollama pull qwen2.5:32b
ollama pull phi4:latest
ollama pull mistral:7b
ollama pull llama3.1:8b

# 5. Start KISYSTEM
python start_kisystem.py
```

### First Task

```python
# Simple Python Task
>>> erstelle eine Funktion zum Addieren zweier Zahlen

# CUDA Task (triggers Meta-Supervisor)
>>> baue einen CUDA Kernel fÃ¼r Vektor-Addition

# Autonomous Build (mit Auto-Test-Fix Loop)
>>> baue autonom: CUDA Matrix-Multiplikation mit Shared Memory
```

### Check Statistics

```python
>>> stats

# Output:
Meta-Supervisor Statistics:
  Total Tasks: 47
  Success Rate: 89.4%
  Avg Solution Time: 127s
  
Domain Performance:
  CUDA/Kernel:   92% success, avg 156s
  C++/System:    88% success, avg 98s
  Audio/DSP:     94% success, avg 112s
  
Model Effectiveness:
  qwen2.5-coder:32b  â†’ 94% success (CUDA preferred)
  deepseek-coder:16b â†’ 87% success (C++ preferred)
  deepseek-r1:32b    â†’ 91% success (Deep fixes)
```

---

## ğŸ“Š Performance Metrics

### Typical Build-Test-Fix Loop

| Phase | Time | Model | Status |
|-------|------|-------|--------|
| **Parse & Route** | <1s | - | Supervisor |
| **Priority Analysis** | <0.5s | - | Meta-Supervisor |
| **Model Selection** | <0.5s | - | Hybrid Decision |
| **Code Generation** | 2-180s | Selected | Builder |
| **Compilation** | 5-30s | - | nvcc/gcc |
| **Test Execution** | 2-10s | - | Tester |
| **Tier 0 Profile** | <5s | - | Microbench |
| **Tier 1 Profile** | 30-60s | - | nsys (if needed) |
| **Learning Update** | <1s | - | Learning Module |

**Total (Simple Task):** ~30s  
**Total (Medium Task):** ~2min  
**Total (Complex Task):** ~7min (with 32B models)

### Phase 7 Improvements vs Phase 6

| Metric | Phase 6 | Phase 7 | Improvement |
|--------|---------|---------|-------------|
| **Model Selection** | Static rules | Data-driven | +15% accuracy |
| **Profiling Time** | Always full | Two-Tier | -45% time |
| **Task Priority** | FIFO | Cost-Aware | +30% efficiency |
| **Error Recovery** | Retry same | Stop-Loss Escalation | -25% failed tasks |
| **Learning Speed** | Linear | Exponential aging | Better recency |

---

## ğŸ“– Documentation

### Core Guides
- **[QUICKSTART.md](docs/QUICKSTART.md)** - Schnellstart fÃ¼r RUN 32
- **[PHASE7_GUIDE.md](docs/PHASE7_GUIDE.md)** - Detaillierte Phase 7 Features
- **[INDEX.md](docs/INDEX.md)** - Dokumentations-Index

### Technical Specs
- **[KISYSTEM_Optimization_Spec_v7.md](docs/specs/KISYSTEM_Optimization_Spec_v7.md)** - Phase 7 Specification
- **[CLAUDE_INSTRUCTIONS.md](CLAUDE_INSTRUCTIONS.md)** - Session Memory & Development Rules

### Feature Documentation
- **[README_LEARNING_V2.md](docs/core-features/README_LEARNING_V2.md)** - Context-Aware Learning
- **[README_WORKFLOW.md](docs/core-features/README_WORKFLOW.md)** - Auto-Dependency Management
- **[IMPLEMENTATION_SUMMARY.md](docs/core-features/IMPLEMENTATION_SUMMARY.md)** - Auto-Dependency Implementation

### API Reference
```python
# Coming soon - Phase 7 API Documentation
```

---

## ğŸµ U3DAW Project - The Big Picture

### Vision
**Universal 3D Audio Workstation** mit GPU-beschleunigter Raumkorrektur, die kommerzielle LÃ¶sungen wie Trinnov Altitude 32 (â‚¬25k+) Ã¼bertrifft.

### TEP Innovation (Time-Energy Processing)

**Problem mit traditionellen FIR-Filtern:**
- Hohe Latenz (50-85ms)
- Massive Energieverschwendung (Brute-Force Inverse Filtering)
- Pre-Ringing Artefakte (20-40ms)
- Ignoriert Lautsprecher-Physik

**TEP Revolution:**
- **Latenz:** <5ms End-to-End (vs 85ms FIR)
- **Energie:** 75% weniger als FIR (kooperativ statt invers)
- **Pre-Ringing:** <1ms (vs 20-40ms)
- **Ansatz:** Adaptive Time-Frequency-Local Processing
- **Philosophie:** Kooperiere mit dem Lautsprecher, zwinge ihn nicht

### Technical Targets
- **GPU Load:** <25% @ 32ch/192kHz
- **Energy Savings:** â‰¥25% vs equivalent FIR
- **Phase Coherence:** <10Âµs (vs 50-100Âµs FIR)
- **SPL Efficiency:** +2-3dB from energy optimization

### KISYSTEM's Role
1. Generiere CUDA-Kernels fÃ¼r TEP-Algorithmen
2. Teste auf echter Hardware (RME MADI FX + RTX 4070)
3. Optimiere Performance iterativ
4. Lerne aus jedem Build-Test-Fix-Zyklus
5. Beschleunige Entwicklung um Faktor 10+

---

## ğŸ”’ Security & Safety

### Learning Database
- **Location:** `D:\AGENT_MEMORY\memory.db`
- **Backup:** Automatisch bei jedem Update
- **Privacy:** Nur lokale Speicherung, keine Cloud

### Code Execution
- **Sandbox:** Isolated execution environment
- **Validation:** Multi-stage testing before deployment
- **Rollback:** Automatic bei kritischen Fehlern

### Dependencies
- **Whitelist:** 24 pre-approved packages (numpy, scipy, etc.)
- **PyPI Validation:** Automatic fÃ¼r unbekannte Packages
- **User Confirmation:** Bei kritischen Dependencies

---

## ğŸ› ï¸ Development Workflow

### Daily Development Cycle

```
Morning:
  â†’ Start KISYSTEM
  â†’ Review Meta-Supervisor priorities
  â†’ Work on highest-priority tasks

Development:
  â†’ "baue autonom: [task]" fÃ¼r komplexe Features
  â†’ "erstelle: [task]" fÃ¼r simple code-gen
  â†’ System lernt automatisch aus jedem Run

Testing:
  â†’ Automatic durch Tester Agent
  â†’ Hardware-in-the-Loop bei Audio/CUDA
  â†’ Two-Tier-Profiling fÃ¼r Performance

Evening:
  â†’ Check statistics: "stats"
  â†’ Review learned solutions
  â†’ Backup & Commit
```

### Best Practices

âœ… **DO:**
- Use "baue autonom" fÃ¼r kritische CUDA/C++ Tasks
- Let Meta-Supervisor choose models (data-driven)
- Review statistics regularly
- Extend whitelist fÃ¼r project-specific dependencies
- Clear `__pycache__` before testing Python changes

âŒ **DON'T:**
- Never use `llama3.1:8b` for CUDA tasks (quality issues)
- Don't override Meta-Supervisor without good reason
- Don't skip cache clearing (leads to old code execution)
- Don't proceed with errors in early steps (fix immediately)
- No speculation - ask when uncertain

---

## ğŸ“ˆ Project Status

### Completed (Phase 6 & Earlier)
- âœ… Learning Module V2 (Context-Aware)
- âœ… Confidence Scorer (Multi-Factor)
- âœ… Workflow Engine (Auto-Dependencies)
- âœ… Smart Model Selector (Complexity Detection)
- âœ… Performance Parser (GPU Metrics)
- âœ… Error Categorizer (4 Categories)
- âœ… 7 Ollama Models integrated
- âœ… ASIO Wrapper functional
- âœ… 32-Channel GUI with VU-Meters

### In Progress (Phase 7 - RUN 32)
- ğŸ”„ Meta-Supervisor Implementation
- ğŸ”„ Hybrid Decision Logic
- ğŸ”„ Two-Tier-Profiling System
- ğŸ”„ Cost-Aware Queue
- ğŸ”„ OptimizationConfig Integration

### Planned (Phase 8+)
- ğŸ“‹ TEP Algorithm Implementation
- ğŸ“‹ Acourate Integration
- ğŸ“‹ Multi-Channel Sync
- ğŸ“‹ Real-Time Convolution Engine
- ğŸ“‹ Hardware-in-the-Loop Automation

---

## ğŸ› Known Issues

### Critical
1. **nsys Profiling** - CUDAProfiler kann keine Metriken extrahieren
   - Workaround: Two-Tier-Profiling (Tier 0 = Microbench)
   - Status: Phase 7 adressiert dies

2. **llama3.1:8b Quality** - Generiert broken CUDA code
   - Workaround: Nie fÃ¼r CUDA verwenden
   - Status: In 7-Model-Routing dokumentiert

### Minor
3. **Unicode Decode** - Thread exception in subprocess
   - Impact: Log noise, non-blocking
   - Status: Low priority

---

## ğŸ“ Support & Contact

**Developer:** JÃ¶rg Bohne  
**Company:** Bohne Audio  
**Location:** Engelskirchen, Germany  
**Email:** [contact via GitHub]  
**GitHub:** https://github.com/JoeBoh71/KISYSTEM

### Getting Help

1. **Documentation:** Start with [INDEX.md](docs/INDEX.md)
2. **Quick Issues:** Check [CLAUDE_INSTRUCTIONS.md](CLAUDE_INSTRUCTIONS.md)
3. **GitHub Issues:** For bugs and feature requests
4. **Debugging:** Enable verbose logging: `config.verbose = True`

---

## ğŸ“œ License

**Proprietary - JÃ¶rg Bohne / Bohne Audio**  
Not for public distribution.

TEP Technology: Patent pending / Trade secret

---

## ğŸ™ Credits

**Design & Architecture:** JÃ¶rg Bohne  
**Implementation:** Claude (Anthropic) + JÃ¶rg Bohne  
**Testing Environment:** U3DAW Development System  
**Hardware:** Bohne Audio Reference System

---

## ğŸ¯ Success Metrics (Phase 7 Goals)

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Compilation Success | >90% | - | ğŸ”„ Testing |
| Model Selection Accuracy | >70% | - | ğŸ”„ Meta-Supervisor |
| Profiling Time Reduction | 40-55% | - | ğŸ”„ Two-Tier |
| Error Recovery Rate | +25% | - | ğŸ”„ Stop-Loss |
| Task Efficiency (ROI) | +30% | - | ğŸ”„ Cost-Aware Queue |

---

**Status:** ğŸš€ Phase 7 Implementation Active  
**Version:** RUN 32  
**Last Updated:** 2025-11-10  
**Quality:** â­â­â­â­â­

**KISYSTEM - Autonomous Development for the Future of Audio**
