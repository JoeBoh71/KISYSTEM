# KISYSTEM Optimization Spec v7
**Version:** 7.0â€ƒâ€ƒ**Status:** Phase-7â€ƒâ€ƒ**Datum:** 2025-11-10  

---

## 1. Zielsetzung
KISYSTEM v7 entwickelt das bestehende Framework zu einem **proaktiven, lernfÃ¤higen Build- und Optimierungssystem** weiter.  
Hauptziele:
- EinfÃ¼hrung des **Meta-Supervisors** zur datenbasierten Priorisierung und Modellwahl  
- Integration des **7-Modell-Routings** mit Stop-Loss-Eskalation  
- Parametrische Steuerung von QualitÃ¤t / Durchsatz / Lernverhalten  
- Asynchrone Verarbeitung und Kosten-/Zeit-Optimierung  

---

## 2. Meta-Supervisor
**Aufgabe:** Analyse der Laufstatistiken aus `learning_module_v2`, Berechnung von PrioritÃ¤ten und Modell-Bias (read-only).

**Ausgaben**
```python
next_priorities() -> List[str]
recommend_model_bias() -> Dict[str, str]


PrioritÃ¤tsformel
ğ‘ƒ
(
ğ‘‘
)
=
0.5
(
1
âˆ’
ğ‘ 
ğ‘Ÿ
)
+
0.2
/
(
1
+
ğ‘¡
)
+
0.2
min
â¡
(
1
,
ğ‘
/
20
)
+
0.1
ğ‘…
P(d)=0.5(1âˆ’sr)+0.2/(1+t)+0.2min(1,c/20)+0.1R

sr â€“ Erfolgsquote

t â€“ Durchschnittliche LÃ¶sungszeit

c â€“ Anzahl DurchlÃ¤ufe

R â€“ RecencyBoost (+0.1 bei neuem Fehler < 3 Tage, âˆ’0.1 bei Erfolg < 1 Tag)

Modell-Bias
ğ‘
ğ‘’
ğ‘ 
ğ‘¡
_
ğ‘š
ğ‘œ
ğ‘‘
ğ‘’
ğ‘™
(
ğ‘‘
)
=
arg
â¡
max
â¡
ğ‘š
(
ğ‘ 
ğ‘Ÿ
ğ‘š
,
ğ‘‘
)
wenn 
ğ‘ 
ğ‘Ÿ
â‰¥
0.65
,
â€‰
ğ‘
ğ‘œ
ğ‘¢
ğ‘›
ğ‘¡
â‰¥
5
best_model(d)=arg
m
max
	â€‹

(sr
m,d
	â€‹

)wenn srâ‰¥0.65,countâ‰¥5

â†’ liefert bevorzugtes Startmodell pro DomÃ¤ne.

3. Modell-Inventar (7 Modelle)
Rang	Modell	Rolle	Timeout [s]
1	llama3.1:8b	Trivial / Boilerplate	180
2	mistral:7b	Generisch / Kurz	240
3	phi4:latest	Tests / Specs / Docs	240
4	deepseek-coder-v2:16b	Mid-Coding C++ / CUDA	300
5	qwen2.5:32b	Reasoning / Architektur	900
6	qwen2.5-coder:32b	Komplexes Coding / CUDA-Opt	1800
7	deepseek-r1:32b	Deep Fixes / Reasoning	1800
4. DomÃ¤nen-Routing und Eskalation
DomÃ¤ne	Start-Modell	Eskalations-Kette (Stop-Loss = 2 Fails)
CUDA / Kernel	qwen2.5-coder	r1 â†’ coder-v2 â†’ qwen2.5
C++ / System	coder-v2	qwen-coder â†’ r1 â†’ qwen2.5
Audio / DSP	coder-v2	qwen-coder â†’ r1
Tests / Docs	phi4	mistral â†’ llama â†’ qwen
Planung / Refactor	qwen2.5	r1 â†’ mistral

Success-Matrix Ã¼berschreibt Startmodell, wenn success â‰¥ 0.65 âˆ§ count â‰¥ 5.
Ã„ltere Runs â†’ Gewicht = exp(âˆ’age / 30).

5. Parametrisierung (OptimizationConfig)
SchlÃ¼ssel	Typ / Bereich	Default	Bedeutung
max_optimization_iterations	int [1â€“50]	10	Maximale Fix/Optimize-Schleifen
target_score	int [0â€“100]	80	Zielwert aus PerformanceParser
retry_build / retry_test / retry_profile	int	2 / 1 / 1	Wiederholungen pro Phase
stoploss_per_model	int [1â€“5]	2	Fehler-Limit pro Modell
max_concurrent_builds	int [1â€“8]	3	Parallel-Build-Semaphore
enable_meta_supervisor	bool	True	PrioritÃ¤t / Bias aktivieren
6. Performance-Strategien
Retry-Budget und Stop-Loss

Build/Test/Profile = 2 / 1 / 1 â†’ Eskalation nach 2 FehlschlÃ¤gen.

Two-Tier-Profiling

Tier 0 â€“ Microbench (ohne nsys)

Tier 1 â€“ Vollprofil nur bei relevanter AktivitÃ¤t
â†’ Profilingzeit âˆ’40 bis âˆ’55 %

Cost-Aware Queue
ğ‘ƒ
ğ‘Ÿ
ğ‘–
ğ‘œ
ğ‘Ÿ
ğ‘–
ğ‘¡
ğ‘¦
ğ¸
ğ‘“
ğ‘“
=
ğ‘ƒ
ğ‘Ÿ
ğ‘–
ğ‘œ
ğ‘Ÿ
ğ‘–
ğ‘¡
ğ‘¦
ğ‘†
ğ‘
ğ‘œ
ğ‘Ÿ
ğ‘’
ğ¸
ğ‘‡
ğ´
(
ğ‘€
ğ‘œ
ğ‘‘
ğ‘’
ğ‘™
,
ğ·
ğ‘œ
ğ‘š
ğ‘
Â¨
ğ‘›
ğ‘’
)
PriorityEff=
ETA(Model,Dom
a
Â¨
ne)
PriorityScore
	â€‹


â†’ Aufgaben mit hÃ¶chstem ROI zuerst.

Async I/O

nvcc / Tests non-blocking, Profiler seriell

Timeouts [s] = Build 300, Test 120, Profiler 900

7. Scoring und Logging

Scorebereich 0â€“100â€ƒ(typisch 80â€“90, >95 nur nach Tuning).
Lernlogging bei jedem Exit:


run_id, domain, model, iter, score_final, outcome,
phase, reason, timings:{build,test,profile}, ts


run_id, domain, model, iter, score_final, outcome,
phase, reason, timings:{build,test,profile}, ts

